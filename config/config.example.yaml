# ════════════════════════════════════════════════════════════════════════════
# FUSIONN-MUSE CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════
# Subtitle transcription and translation pipeline for qBittorrent

server:
  port: 8080

# ─────────────────────────────────────────────────────────────────────────────
# WHISPER (Transcription)
# ─────────────────────────────────────────────────────────────────────────────
# Transcribe video audio to subtitles.
#
# Providers:
#   - "local"  : Uses whisper.cpp (bundled in Docker image)
#   - "openai" : Uses OpenAI Whisper API (requires api_key)
whisper:
  # Provider: "local" or "openai"
  provider: "local"

  # Model (downloaded automatically if not present):
  #   local  = "tiny", "base", "small", "medium", "large-v2", "large-v3"
  #   openai = "whisper-1"
  # Note: First run with a new model will download it (~1-3GB depending on size)
  model: "large-v2"

  # API key (required for openai provider)
  api_key: ""

  # Source language hint (optional, "" or "auto" for auto-detect)
  # Examples: "en", "ja", "zh", "ko"
  language: ""

  # Initial prompt for context (optional)
  # Helps improve accuracy by providing topic, proper nouns, or expected content
  # Examples:
  #   - "This is a Japanese anime about cooking."
  #   - "Technical discussion about Kubernetes and Docker."
  #   - "名前: 田中太郎, 山田花子" (for proper name recognition)
  prompt: ""

  # ─── Post-processing (like VideoCaptioner) ───
  # Uses the translate LLM settings below

  # Use LLM to fix recognition errors, remove filler words (um, uh, ah)
  optimize_subtitles: false

  # Use LLM to split long subtitles into shorter sentences (断句)
  split_sentences: true

  # Max characters/words per line for sentence splitting
  max_cjk_chars: 25 # Chinese/Japanese/Korean
  max_english_words: 18 # English and other languages (VideoCaptioner default)

  # Remove trailing punctuation (，。) from subtitles
  remove_punctuation: true

# ─────────────────────────────────────────────────────────────────────────────
# TRANSLATE (llm-subtrans)
# ─────────────────────────────────────────────────────────────────────────────
# Translate subtitles using LLM.
# Repo: https://github.com/machinewrapped/llm-subtrans
#
# Providers:
#   - "openai"     : OpenAI API (gpt-4o, gpt-4o-mini, etc.)
#   - "claude"     : Anthropic Claude
#   - "gemini"     : Google Gemini
#   - "openrouter" : OpenRouter (access to many models)
#   - "custom"     : Custom OpenAI-compatible endpoint
translate:
  # Provider
  provider: "openai"

  # Model (depends on provider)
  model: "gpt-4o-mini"

  # API key
  api_key: ""

  # Target language for translation
  target_lang: "Simplified Chinese"

  # ─── Custom endpoint (only for provider: "custom") ───
  # Server URL (e.g., "http://localhost:1234")
  custom_server: ""
  # Endpoint path (e.g., "/v1/chat/completions")
  custom_endpoint: ""

  # ─── Rate limiting ───
  # Requests per minute (0 = no limit)
  # Useful for avoiding rate limit errors or controlling costs
  rate_limit_rpm: 0

  # Custom instruction for the LLM translator (optional)
  # Example: "Preserve Japanese honorifics like -san, -kun, -chan"
  instruction: ""

  # Additional arguments for llm-subtrans (optional)
  args: []

# ─────────────────────────────────────────────────────────────────────────────
# QUEUE
# ─────────────────────────────────────────────────────────────────────────────
queue:
  # Max retries before marking job as failed
  # Failed files are moved to /data/failed for manual inspection
  max_retries: 3

  # Delay between retries (milliseconds)
  retry_delay_ms: 5000

# ─────────────────────────────────────────────────────────────────────────────
# APPRISE (Notifications)
# ─────────────────────────────────────────────────────────────────────────────
apprise:
  enabled: false
  base_url: "http://apprise:8000"
  key: "apprise"
  tag: "fusionn-muse"
# ════════════════════════════════════════════════════════════════════════════
# DOCKER SETUP
# ════════════════════════════════════════════════════════════════════════════
#
# docker run -d \
#   -p 8080:8080 \
#   -v /path/to/downloads:/data/input:ro \
#   -v /path/to/finished:/data/finished \
#   -v /path/to/subtitles:/data/subtitles \
#   -v ./config.yaml:/app/config/config.yaml:ro \
#   fusionn-muse
#
# Internal folders (no need to mount):
#   /data/staging    - Queue before processing
#   /data/processing - Active processing
#   /data/failed     - Failed jobs (mount if you want access)
#
# ════════════════════════════════════════════════════════════════════════════
# QBITTORRENT SETUP
# ════════════════════════════════════════════════════════════════════════════
#
# Options → Downloads → Run external program on completion:
#   /path/to/torrent-complete.sh "%F" "%N" "%L"
#
# torrent-complete.sh:
#   #!/bin/bash
#   curl -X POST http://fusionn-muse:8080/api/v1/webhook/torrent \
#     -H "Content-Type: application/json" \
#     -d "{\"path\": \"$1\", \"name\": \"$2\", \"category\": \"$3\"}"
#
# ════════════════════════════════════════════════════════════════════════════
# API ENDPOINTS
# ════════════════════════════════════════════════════════════════════════════
#
# POST /api/v1/webhook/torrent     - qBittorrent completion callback
# GET  /api/v1/queue               - List all jobs
# GET  /api/v1/queue/stats         - Queue statistics
# GET  /api/v1/queue/:id           - Get job details
# POST /api/v1/retry/staging       - Re-queue all staging files
# POST /api/v1/retry/failed        - Re-queue all failed files
# POST /api/v1/retry/failed/:name  - Re-queue specific failed file
# GET  /api/v1/files/staging       - List staging files
# GET  /api/v1/files/failed        - List failed files
#
# ════════════════════════════════════════════════════════════════════════════
