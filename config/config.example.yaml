# ════════════════════════════════════════════════════════════════════════════
# FUSIONN-MUSE CONFIGURATION
# ════════════════════════════════════════════════════════════════════════════
# Subtitle transcription and translation pipeline for qBittorrent

server:
  port: 8080

# Skip transcription & translation for testing file workflow
dry_run: false

# ─────────────────────────────────────────────────────────────────────────────
# WHISPER (Transcription)
# ─────────────────────────────────────────────────────────────────────────────
# Transcribe video audio to subtitles using VideoCaptioner's FasterWhisperASR.
#
# Features:
#   - Hallucination filtering (removes common ASR artifacts)
#   - VAD filtering with configurable method/threshold
#   - Auto CJK (30 chars) vs Latin (90 chars) line width
#   - Timing optimization
whisper:
  # Model (downloaded automatically if not present):
  #   "tiny", "base", "small", "medium", "large-v2", "large-v3", "large-v3-turbo"
  # Note: First run with a new model will download it (~1-3GB depending on size)
  model: "large-v2"

  # Source language hint (optional, "" or "auto" for auto-detect)
  # Examples: "en", "ja", "zh", "ko"
  language: ""

  # Initial prompt for context (optional)
  # Helps improve accuracy by providing topic, proper nouns, or expected content
  # Examples:
  #   - "This is a Japanese anime about cooking."
  #   - "Technical discussion about Kubernetes and Docker."
  #   - "名前: 田中太郎, 山田花子" (for proper name recognition)
  prompt: ""

  # ─── FasterWhisper Settings ───

  # Device for inference: "cuda" (GPU), "cpu", or "auto" (recommended)
  # Auto will use CUDA if available, otherwise CPU
  device: "auto"

  # Voice Activity Detection (VAD) - filters out non-speech audio (uses Silero VAD)
  vad_filter: true
  vad_threshold: 0.5 # 0.0-1.0, lower = more sensitive

  # ─── Post-processing (like VideoCaptioner) ───
  # Uses the translate LLM settings below

  # Use LLM to fix recognition errors, remove filler words (um, uh, ah)
  optimize_subtitles: false

  # Use LLM to split long subtitles into shorter sentences (断句)
  split_sentences: true

  # Max characters/words per line for sentence splitting
  max_cjk_chars: 25 # Chinese/Japanese/Korean
  max_english_words: 18 # English and other languages (VideoCaptioner default)

  # Remove trailing punctuation (，。) from subtitles
  remove_punctuation: true

# ─────────────────────────────────────────────────────────────────────────────
# TRANSLATE (VideoCaptioner LLM Translator)
# ─────────────────────────────────────────────────────────────────────────────
# Translate subtitles using LLM with batch processing and validation.
# Based on VideoCaptioner's translation engine with:
#   - Auto-retry on malformed responses
#   - JSON validation and repair
#   - Reflection mode for higher quality
#   - Built-in caching (7-day TTL)
#
# Providers (all OpenAI-compatible):
#   - "openai"       : OpenAI API (gpt-4o, gpt-4o-mini, etc.)
#   - "deepseek"     : DeepSeek API (deepseek-chat, deepseek-reasoner)
#   - "siliconcloud" : SiliconCloud (Qwen, Yi, DeepSeek models)
#   - "openrouter"   : OpenRouter (access to many models)
#   - "groq"         : Groq (fast inference)
#   - "together"     : Together AI
#   - "fireworks"    : Fireworks AI
#   - "custom"       : Custom OpenAI-compatible endpoint
translate:
  # Provider
  provider: "openai"

  # Model (depends on provider)
  model: "gpt-4o-mini"

  # API key
  api_key: ""

  # Target language for translation
  # Options: "Simplified Chinese", "Traditional Chinese", "English", "Japanese",
  #          "Korean", "French", "German", "Spanish", "Russian", etc.
  target_lang: "Simplified Chinese"

  # ─── Custom endpoint (only for provider: "custom") ───
  # Server URL (e.g., "http://localhost:1234")
  custom_server: ""

  # Custom instruction/prompt for translation (optional)
  # Use for terminology, style guidance, or domain-specific instructions
  # Examples:
  #   - "Preserve Japanese honorifics like -san, -kun, -chan"
  #   - "Technical terms: API=接口, server=服务器"
  #   - "Use formal language style"
  instruction: ""

  # ─── Quality settings ───
  # Enable reflection mode for higher quality translation (2-3x slower)
  # LLM translates, then self-critiques and improves the translation
  use_reflect: false

  # Number of parallel translation threads (default: 4)
  threads: 4

  # Number of subtitles per batch (default: 10)
  # Smaller batches = more API calls but better error recovery
  batch_size: 10

# ─────────────────────────────────────────────────────────────────────────────
# QUEUE
# ─────────────────────────────────────────────────────────────────────────────
queue:
  # Max retries before marking job as failed
  # Failed files are moved to /data/failed for manual inspection
  max_retries: 3

  # Delay between retries (milliseconds)
  retry_delay_ms: 5000

# ─────────────────────────────────────────────────────────────────────────────
# APPRISE (Notifications)
# ─────────────────────────────────────────────────────────────────────────────
apprise:
  enabled: false
  base_url: "http://apprise:8000"
  key: "apprise"
  tag: "fusionn-muse"
# ════════════════════════════════════════════════════════════════════════════
# DOCKER SETUP
# ════════════════════════════════════════════════════════════════════════════
#
# docker run -d \
#   -p 8080:8080 \
#   -v /path/to/downloads:/data/torrents:ro \
#   -v /path/to/automation:/data/automation \
#   -v ./config.yaml:/app/config/config.yaml:ro \
#   fusionn-muse
#
# Folder structure:
#   /data/torrents              - Input: torrent download folder (read-only)
#   /data/automation/staging    - Internal: queue before processing
#   /data/automation/processing - Internal: active processing
#   /data/automation/scraping   - Output: videos ready for scraping
#   /data/automation/subtitles  - Output: translated subtitles
#   /data/automation/failed     - Failed jobs (for manual inspection)
#
# ════════════════════════════════════════════════════════════════════════════
# QBITTORRENT SETUP
# ════════════════════════════════════════════════════════════════════════════
#
# Options → Downloads → Run external program on completion:
#   /path/to/torrent-complete.sh "%F" "%N" "%L"
#
# torrent-complete.sh:
#   #!/bin/bash
#   curl -X POST http://fusionn-muse:8080/api/v1/webhook/torrent \
#     -H "Content-Type: application/json" \
#     -d "{\"path\": \"$1\", \"name\": \"$2\", \"category\": \"$3\"}"
#
# ════════════════════════════════════════════════════════════════════════════
# API ENDPOINTS
# ════════════════════════════════════════════════════════════════════════════
#
# POST /api/v1/webhook/torrent     - qBittorrent completion callback
# GET  /api/v1/queue               - List all jobs
# GET  /api/v1/queue/stats         - Queue statistics
# GET  /api/v1/queue/:id           - Get job details
# POST /api/v1/retry/staging       - Re-queue all staging files
# POST /api/v1/retry/failed        - Re-queue all failed files
# POST /api/v1/retry/failed/:name  - Re-queue specific failed file
# GET  /api/v1/files/staging       - List staging files
# GET  /api/v1/files/failed        - List failed files
#
# ════════════════════════════════════════════════════════════════════════════
