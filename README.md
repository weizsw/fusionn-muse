# Fusionn-Muse

Automatic subtitle transcription and translation pipeline for qBittorrent. When a torrent completes, Fusionn-Muse transcribes the audio using FasterWhisper and translates subtitles to your target language using LLM APIs.

## Features

- ğŸ¤ **FasterWhisper Transcription** - GPU-accelerated speech-to-text with hallucination filtering
- ğŸŒ **LLM Translation** - OpenAI-compatible APIs (OpenAI, DeepSeek, Groq, SiliconCloud, etc.)
- ğŸ“¥ **qBittorrent Integration** - Webhook triggers processing on torrent completion
- ğŸ”„ **Hot-Reload Config** - Change settings without restarting
- ğŸ“ **Smart File Detection** - Filters ads/samples by size and filename patterns
- ğŸ”” **Notifications** - Apprise integration (Telegram, Discord, email, etc.)

## Quick Start

### Docker (Recommended)

```bash
docker run -d \
  -p 8080:8080 \
  -v /path/to/downloads:/data/torrents:ro \
  -v /path/to/automation:/data/automation \
  -v ./config.yaml:/app/config/config.yaml:ro \
  ghcr.io/your-username/fusionn-muse:latest
```

### Docker Compose

```yaml
services:
  fusionn-muse:
    image: ghcr.io/your-username/fusionn-muse:latest
    ports:
      - "8080:8080"
    volumes:
      - /path/to/downloads:/data/torrents:ro
      - /path/to/automation:/data/automation
      - ./config.yaml:/app/config/config.yaml:ro
    environment:
      - ENV=production
    restart: unless-stopped
```

## Configuration

Copy the example config and customize:

```bash
cp config/config.example.yaml config.yaml
```

### Key Settings

```yaml
whisper:
  model: "large-v2"           # tiny, base, small, medium, large-v2, large-v3
  language: "ja"              # Source language hint (or "" for auto-detect)
  device: "auto"              # cuda, cpu, or auto

translate:
  provider: "openai"          # openai, deepseek, siliconcloud, groq, etc.
  model: "gpt-4o-mini"
  api_key: "sk-..."
  target_lang: "Simplified Chinese"
```

See [config.example.yaml](config/config.example.yaml) for full documentation.

## qBittorrent Setup

1. Go to **Options â†’ Downloads â†’ Run external program on torrent completion**

2. Add the command:

   ```bash
   curl -X POST http://fusionn-muse:8080/api/v1/webhook/torrent \
     -H "Content-Type: application/json" \
     -d '{"path": "%F", "name": "%N", "category": "%L"}'
   ```

   Or use the provided script: `scripts/torrent-complete.sh`

## Folder Structure

```
/data/
â”œâ”€â”€ torrents/              # Input: torrent download folder (read-only)
â””â”€â”€ automation/
    â”œâ”€â”€ staging/           # Queue: waiting for processing
    â”œâ”€â”€ processing/        # Active: currently being processed
    â”œâ”€â”€ scraping/          # Output: videos ready for media server
    â”œâ”€â”€ subtitles/         # Output: translated .srt files
    â””â”€â”€ failed/            # Failed jobs (manual inspection)
```

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/webhook/torrent` | qBittorrent completion callback |
| GET | `/api/v1/queue` | List all jobs |
| GET | `/api/v1/queue/stats` | Queue statistics |
| GET | `/api/v1/queue/:id` | Get job details |
| POST | `/api/v1/retry/staging` | Re-queue all staging files |
| POST | `/api/v1/retry/failed` | Re-queue all failed files |
| POST | `/api/v1/retry/failed/:name` | Re-queue specific failed file |
| GET | `/api/v1/files/staging` | List staging files |
| GET | `/api/v1/files/failed` | List failed files |
| GET | `/api/v1/health` | Health check |
| GET | `/api/v1/version` | Version info |

## Video File Filtering

When processing a folder, Fusionn-Muse automatically filters out ads and samples:

- **Size filter**: Files â‰¤200MB are skipped
- **Pattern filter**: Must contain a valid code pattern (e.g., `SONE-269`, `JUR-123`)
- **Selection**: Largest valid file is selected

### Chinese Subtitle Detection

Files with Chinese subtitle indicators are skipped (already have subtitles):

- Suffixes: `-C`, `_C`, `.C`
- Language codes: `zh`, `chs`, `cht`, `chi`, `cn`, `gb`, `big5`, `sc`, `tc`
- Chinese terms: `ä¸­æ–‡`, `ç®€ä¸­`, `ç¹ä¸­`, `è½¯ä¸­`, `ç¡¬ä¸­`, `å­—å¹•`, `å†…åµŒ`, `å†…å°`, `ä¸­å­—`, `å›½è¯­`, `åŒè¯­`

## LLM Providers

All providers use OpenAI-compatible API:

| Provider | Base URL | Models |
|----------|----------|--------|
| `openai` | api.openai.com | gpt-4o, gpt-4o-mini |
| `deepseek` | api.deepseek.com | deepseek-chat, deepseek-reasoner |
| `siliconcloud` | api.siliconflow.cn | Qwen, Yi, DeepSeek |
| `groq` | api.groq.com | llama, mixtral |
| `openrouter` | openrouter.ai | Many models |
| `together` | api.together.xyz | Various |
| `fireworks` | api.fireworks.ai | Various |
| `custom` | Your endpoint | Any OpenAI-compatible |

## Development

### Prerequisites

- Go 1.23+
- Python 3.11+ (for transcription/translation scripts)
- Docker (for building images)

### Build

```bash
# Build binary
make build

# Run locally
make run

# Run tests
make test

# Build Docker image
make docker
```

### Project Structure

```
fusionn-muse/
â”œâ”€â”€ cmd/fusionn-muse/       # Entry point
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ config/             # Configuration management
â”‚   â”œâ”€â”€ handler/            # HTTP handlers (Gin)
â”‚   â”œâ”€â”€ service/processor/  # Processing pipeline
â”‚   â”œâ”€â”€ executor/           # Whisper & translator wrappers
â”‚   â”œâ”€â”€ queue/              # Job queue
â”‚   â”œâ”€â”€ fileops/            # File operations
â”‚   â””â”€â”€ client/apprise/     # Notification client
â”œâ”€â”€ pkg/logger/             # Logging utilities
â”œâ”€â”€ scripts/                # Python scripts
â”‚   â”œâ”€â”€ transcribe.py       # FasterWhisper transcription
â”‚   â”œâ”€â”€ translate.py        # LLM translation
â”‚   â””â”€â”€ subtitle_processor.py # Post-processing
â””â”€â”€ config/
    â””â”€â”€ config.example.yaml # Example configuration
```

## License

MIT
